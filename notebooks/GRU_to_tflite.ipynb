{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i862304/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import load_model\n",
    "\n",
    "from src.nn_settings.gru_tflite_config import Config\n",
    "from src.tflite_rnn import convertible_gru #, gru_functional, lstm_functional, tflite_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Data set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i862304/workspace/NeuralNetworkPlayground/notebooks/src/dataset_builders/text_data.py:59: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  sample_data = np.vstack((get_one_sample() for _ in range(data_size)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Vocabulary\n",
      "Building Encoding\n",
      "data_size 30000\n",
      "char_string abcdeXY\n",
      "batch_size 32\n",
      "epochs 4\n",
      "latent_dim 8\n",
      "\n",
      "input chars 9\n",
      "data size 30000\n",
      "[['caXbcYbd' 'bc']\n",
      " ['cdXbcYbe' 'bc']\n",
      " ['ccXecYcc' 'ec']\n",
      " ['bbXccYce' 'cc']\n",
      " ['ecXebYae' 'eb']]\n"
     ]
    }
   ],
   "source": [
    "keras_file = \"../data/keras_rnn_1.h5\"\n",
    "\n",
    "config = Config()\n",
    "data = config.data\n",
    "num_input_characters = config.num_input_characters\n",
    "num_output_characters = config.num_output_characters\n",
    "input_encoding = config.input_encoding\n",
    "output_encoding = config.output_encoding\n",
    "enc = config.encoder\n",
    "max_input_length = enc.max_input_length\n",
    "max_output_length = enc.max_output_length\n",
    "\n",
    "print(\"data_size\", config.data_config.data_size)\n",
    "print(\"char_string\", config.data_config.char_string)\n",
    "\n",
    "batch_size = config.batch_size\n",
    "epochs = config.epochs\n",
    "latent_dim = config.latent_dim\n",
    "\n",
    "print(\"batch_size\", batch_size)\n",
    "print(\"epochs\", epochs)\n",
    "print(\"latent_dim\", latent_dim)\n",
    "\n",
    "print(\"\\ninput chars\", num_input_characters)\n",
    "print(\"data size\", len(data))\n",
    "print(data[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.keras.models import Model, Sequential\n",
    "# from tensorflow.python.keras.layers import Input, GRU, Dense, LSTM\n",
    "# from tensorflow.python.keras.regularizers import l2\n",
    "# from tensorflow.python.keras.layers import TimeDistributed, Bidirectional, RepeatVector\n",
    "# from tensorflow.python.keras.optimizers import RMSprop\n",
    "\n",
    "# def temp_gru(input_size, \n",
    "#              output_size,\n",
    "#              latent_dim,\n",
    "#              max_input_length, \n",
    "#              max_out_seq_len,\n",
    "#              use_bidirectional=False,\n",
    "#             ):\n",
    "#     \"\"\"\n",
    "#     A simple GRU stripped down about as much as possible\n",
    "#     \"\"\"\n",
    "#     inputs = Input(shape=(max_input_length, input_size,))\n",
    "#     if use_bidirectional:\n",
    "#         x = Bidirectional(\n",
    "#                 GRU(latent_dim,\n",
    "#                     return_sequences=False,\n",
    "#                     unroll=True,\n",
    "#                 ),\n",
    "#                 merge_mode='concat',\n",
    "#             )(inputs)\n",
    "#         latent_dim_2 = latent_dim * 2\n",
    "#     else:\n",
    "#         x = GRU(latent_dim,\n",
    "#                 return_sequences=False,\n",
    "#                 unroll=True,\n",
    "#                )(inputs)\n",
    "#         latent_dim_2 = latent_dim        \n",
    "#     x = RepeatVector(max_out_seq_len)(x)\n",
    "#     x = GRU(latent_dim_2, \n",
    "#             kernel_initializer='glorot_uniform', \n",
    "#             recurrent_initializer='orthogonal',  \n",
    "#             return_sequences=True,\n",
    "#             unroll=True,\n",
    "#            )(x)\n",
    "#     outputs = TimeDistributed(\n",
    "#                 Dense(output_size, activation=\"softmax\")\n",
    "#               )(x)\n",
    "#     model = Model(inputs, outputs)\n",
    "\n",
    "#     rms_prop = RMSprop(\n",
    "#                        rho=0.9,\n",
    "#                        decay=0.0,\n",
    "#                        epsilon=1e-08,\n",
    "#                        )\n",
    "#     model.compile(loss=\"categorical_crossentropy\",\n",
    "#                   optimizer=rms_prop)\n",
    "    \n",
    "#     return model\n",
    "\n",
    "\n",
    "# # latent_dim = 16\n",
    "# model = temp_gru(num_input_characters,\n",
    "#                  num_output_characters,\n",
    "#                  latent_dim,\n",
    "#                  max_input_length, \n",
    "#                  max_output_length,\n",
    "#                 )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 8, 9)              0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 42)                6552      \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 2, 42)             0         \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 2, 42)             10710     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 2, 9)              387       \n",
      "=================================================================\n",
      "Total params: 17,649\n",
      "Trainable params: 17,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 27000 samples, validate on 3000 samples\n",
      "Epoch 1/4\n",
      "27000/27000 [==============================] - 8s 308us/sample - loss: 0.8945 - val_loss: 0.0530\n",
      "Epoch 2/4\n",
      "27000/27000 [==============================] - 6s 221us/sample - loss: 0.0037 - val_loss: 1.1935e-07\n",
      "Epoch 3/4\n",
      "27000/27000 [==============================] - 6s 206us/sample - loss: 1.1925e-07 - val_loss: 1.1922e-07\n",
      "Epoch 4/4\n",
      "27000/27000 [==============================] - 6s 209us/sample - loss: 1.1921e-07 - val_loss: 1.1921e-07\n"
     ]
    }
   ],
   "source": [
    "model = convertible_gru(num_input_characters,\n",
    "                 num_output_characters,\n",
    "                 latent_dim,\n",
    "                 max_input_length, \n",
    "                 max_output_length,\n",
    "                )\n",
    "\n",
    "# model = gru_functional(\n",
    "#            num_input_characters,\n",
    "#            num_output_characters,\n",
    "#            latent_dim,\n",
    "#            max_input_length,\n",
    "#            max_output_length,\n",
    "#           )\n",
    "\n",
    "# model = lstm_functional(\n",
    "#            num_input_characters,\n",
    "#            num_output_characters,\n",
    "#            latent_dim,\n",
    "#            max_input_length,\n",
    "#            max_output_length,\n",
    "#           )\n",
    "\n",
    "# model = tflite_lstm(\n",
    "#            num_input_characters,\n",
    "#            num_output_characters,\n",
    "#            latent_dim,\n",
    "#            max_input_length,\n",
    "#            max_output_length,\n",
    "#           )\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(input_encoding, \n",
    "          output_encoding,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.1)\n",
    "\n",
    "model.save(keras_file)\n",
    "# tf.keras.models.save_model(model, keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[9.3975641e-06 7.9116026e-06 9.0582979e-01 8.2582325e-02 8.1784846e-03\n",
      "   4.1360719e-05 3.3343162e-03 8.6330119e-06 7.8870062e-06]\n",
      "  [1.1875411e-07 1.5408457e-07 6.8946034e-02 1.9312893e-04 9.2969137e-01\n",
      "   6.5857741e-05 1.1030507e-03 1.5557679e-07 9.4823427e-08]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'ac'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Demonstrate that the model does something\n",
    "test_sample = \"acXacYda\"\n",
    "test_enc = enc.encode([test_sample], encode_as=\"input\")\n",
    "keras_pred = model.predict(test_enc)\n",
    "print(keras_pred)\n",
    "enc.decode(keras_pred, decode_as=\"output\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/i862304/anaconda3/lib/python3.6/site-packages/tensorflow/lite/python/lite.py:591: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From /Users/i862304/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "INFO:tensorflow:Froze 8 variables.\n",
      "INFO:tensorflow:Converted 8 variables to const ops.\n",
      "Writing model data to file ...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "## Convert to TensorFlow Lite model.\n",
    "tflite_file = \"../data/tflite_rnn_1.h5\"\n",
    "\n",
    "## These docs describe the converter in the TensorFlow nightly release, installed using pip install tf-nightly\n",
    "# converter = tf.lite.TFLiteConverter.from_keras_model_file(keras_file)\n",
    "\n",
    "## For tensorflow 1.12 it should be \n",
    "converter = tf.contrib.lite.TFLiteConverter.from_keras_model_file(keras_file)\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "print(\"Writing model data to file ...\")\n",
    "open(tflite_file, \"wb\").write(tflite_model)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ss = \"RuntimeError: TOCO failed see console for info.\\nb'2019-02-13 14:45:21.834947: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: TensorArrayV3\\n2019-02-13 14:45:21.835013: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1127] Op node missing output type attribute: gru/TensorArray\\n2019-02-13 14:45:21.835033: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: TensorArrayV3\\n2019-02-13 14:45:21.835050: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1127] Op node missing output type attribute: gru/TensorArray_1\\n2019-02-13 14:45:21.835121: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: TensorArrayScatterV3\\n2019-02-13 14:45:21.835139: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1127] Op node missing output type attribute: gru/TensorArrayUnstack/TensorArrayScatter/TensorArrayScatterV3\\n2019-02-13 14:45:21.835168: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: Enter\\n2019-02-13 14:45:21.835194: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: Enter\\n2019-02-13 14:45:21.835213: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: Enter\\n2019-02-13 14:45:21.835231: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: Enter\\n2019-02-13 14:45:21.835274: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: Enter\\n2019-02-13 14:45:21.835297: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: Enter\\n2019-02-13 14:45:21.835320: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: LoopCond\\n2019-02-13 14:45:21.835332: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1127] Op node missing output type attribute: gru/while/LoopCond\\n2019-02-13 14:45:21.835389: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: TensorArrayReadV3\\n2019-02-13 14:45:21.835409: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: Enter\\n2019-02-13 14:45:21.835424: I tensorflow/contrib/lite/toco/import_tensorflow.cc:189] Unsupported data type in placeholder op: 20\\n2019-02-13 14:45:21.835440: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: Enter\\n2019-02-13 14:45:21.835458: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: ReadVariableOp\\n2019-02-13 14:45:21.835475: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: Enter\\n2019-02-13 14:45:21.835489: I tensorflow/contrib/lite/toco/import_tensorflow.cc:189] Unsupported data type in placeholder op: 20\\n2019-02-13 14:45:21.835548: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: ReadVariableOp\\n2019-02-13 14:45:21.835602: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: ReadVariableOp\\n2019-02-13 14:45:21.835657: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: ReadVariableOp\\n2019-02-13 14:45:21.835674: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: Enter\\n2019-02-13 14:45:21.835688: I tensorflow/contrib/lite/toco/import_tensorflow.cc:189] Unsupported data type in placeholder op: 20\\n2019-02-13 14:45:21.835738: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: ReadVariableOp\\n2019-02-13 14:45:21.835790: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: ReadVariableOp\\n2019-02-13 14:45:21.835842: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: ReadVariableOp\\n2019-02-13 14:45:21.835859: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: Enter\\n2019-02-13 14:45:21.835872: I tensorflow/contrib/lite/toco/import_tensorflow.cc:189] Unsupported data type in placeholder op: 20\\n2019-02-13 14:45:21.835921: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: ReadVariableOp\\n2019-02-13 14:45:21.836051: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: ReadVariableOp\\n2019-02-13 14:45:21.836130: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: TensorArrayWriteV3\\n2019-02-13 14:45:21.836145: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1127] Op node missing output type attribute: gru/while/TensorArrayWrite/TensorArrayWriteV3\\n2019-02-13 14:45:21.836162: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: Enter\\n2019-02-13 14:45:21.836176: I tensorflow/contrib/lite/toco/import_tensorflow.cc:189] Unsupported data type in placeholder op: 20\\n2019-02-13 14:45:21.836211: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: Exit\\n2019-02-13 14:45:21.836226: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: Exit\\n2019-02-13 14:45:21.836248: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: TensorArrayReadV3\\n2019-02-13 14:45:21.839639: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 102 operators, 178 arrays (0 quantized)\\n2019-02-13 14:45:21.841691: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 102 operators, 178 arrays (0 quantized)\\n2019-02-13 14:45:21.843801: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 93 operators, 165 arrays (0 quantized)\\n2019-02-13 14:45:21.971145: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 92 operators, 164 arrays (0 quantized)\\n2019-02-13 14:45:21.973872: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 91 operators, 162 arrays (0 quantized)\\n2019-02-13 14:45:21.975570: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 91 operators, 162 arrays (0 quantized)\\n2019-02-13 14:45:21.976779: F tensorflow/contrib/lite/toco/tooling_util.cc:618] Check failed: dim >= 1 (0 vs. 1)\\n'\"\n",
    "# print(ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check performance of tflite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[5.5792561e-04 3.4225883e-04 7.4655816e-02 2.7901456e-01 2.6140375e-02\n",
      "   2.8736067e-01 3.3091739e-01 4.6484091e-04 5.4622925e-04]\n",
      "  [3.3376069e-04 1.8442821e-04 6.3843288e-02 2.7032682e-01 7.3219743e-03\n",
      "   5.0714767e-01 1.5024687e-01 2.6324904e-04 3.3197901e-04]]]\n",
      "b'ed'\n"
     ]
    }
   ],
   "source": [
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.contrib.lite.Interpreter(model_path=tflite_file)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "# change the following line to feed into your own data.\n",
    "# input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "input_data = test_enc.reshape((1,8,9))\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "tflite_pred = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(tflite_pred)\n",
    "print(enc.decode(tflite_pred, decode_as=\"output\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000557926 | 0.000009398 | 0.000548528\n",
      "0.000342259 | 0.000007912 | 0.000334347\n",
      "0.074655816 | 0.905829787 | -0.831173956\n",
      "0.279014558 | 0.082582325 | 0.196432233\n",
      "0.026140375 | 0.008178485 | 0.017961890\n",
      "0.287360668 | 0.000041361 | 0.287319303\n",
      "0.330917388 | 0.003334316 | 0.327583075\n",
      "0.000464841 | 0.000008633 | 0.000456208\n",
      "0.000546229 | 0.000007887 | 0.000538342\n",
      "----------------------------------------\n",
      "0.000333761 | 0.000000119 | 0.000333642\n",
      "0.000184428 | 0.000000154 | 0.000184274\n",
      "0.063843288 | 0.068946034 | -0.005102746\n",
      "0.270326823 | 0.000193129 | 0.270133704\n",
      "0.007321974 | 0.929691374 | -0.922369421\n",
      "0.507147670 | 0.000065858 | 0.507081807\n",
      "0.150246873 | 0.001103051 | 0.149143830\n",
      "0.000263249 | 0.000000156 | 0.000263093\n",
      "0.000331979 | 0.000000095 | 0.000331884\n"
     ]
    }
   ],
   "source": [
    "for ii, (aa, bb) in enumerate(zip(tflite_pred.flatten(), keras_pred.flatten())):\n",
    "    print(\"{:.9f} | {:.9f} | {:.9f}\".format(aa, bb, aa-bb))\n",
    "    if ii == 8:\n",
    "        print(\"--\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
